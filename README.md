ğŸš€ AmbedkarGPT
A Semantic RAG (SemRAG) System for Knowledge-Grounded Question Answering

AmbedkarGPT is a Semantic Retrieval-Augmented Generation (SemRAG) based Question Answering system built on Dr. B. R. Ambedkarâ€™s writings.
Unlike traditional RAG pipelines that rely purely on vector similarity, this system integrates semantic chunking, knowledge graphs, and community-aware retrieval to achieve more accurate, structured, and grounded answers.

This project was implemented as part of the AI Engineering Intern Technical Assignment for Kalpit Pvt. Ltd., with a strong focus on research alignment, practical engineering decisions, and interview-ready execution.

ğŸ¯ Why This Project Is Different

Most RAG systems:
- Split text arbitrarily
- Retrieve chunks independently
- Hallucinate when context is weak
- AmbedkarGPT solves these issues by design.
- Key differentiators:
âœ… Semantic chunking (not fixed-size chunks)
âœ… Knowledge graph for global document structure
âœ… Hybrid local + global retrieval (as proposed in SemRAG)
âœ… Hallucination prevention via relevance gating
âœ… Fully local, low-resource execution



ğŸ§  Core Ideas Implemented (From SemRAG Paper)
This project faithfully implements the core concepts of the SemRAG research paper:

SemRAG Concept	                        Implementation
Algorithm 1	        Semantic chunking using embeddings + cosine similarity
Equation (4)	        Local semantic retrieval using FAISS
Equation (5)	        Global retrieval via graph communities
Global Structure	Knowledge graph with Louvain community detection


ğŸ—ï¸ System Architecture (Conceptual Flow)
                Ambedkar_book.pdf
                        â†“
                Semantic Chunking (Algorithm 1)
                        â†“
                Semantic Chunks
                        â†“
                Entity & Relation Extraction
                        â†“
                Knowledge Graph
                        â†“
                Community Detection (Louvain)
                        â†“
                Hybrid Retrieval
                (Local + Global)
                        â†“
                Context Filtering (Relevance Gate)
                        â†“
                Local LLM (Phi-3)
                        â†“
                Final Answer


ğŸ“‚ Repository Structure: 
ambedkargpt/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Ambedkar_book.pdf
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ chunks.json
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ chunking/          # Semantic chunking (SemRAG Algorithm 1)
â”‚   â”œâ”€â”€ graph/             # Knowledge graph & communities
â”‚   â”œâ”€â”€ retrieval/         # Local & global retrieval
â”‚   â”œâ”€â”€ llm/               # Answer generation
â”‚   â””â”€â”€ pipeline/          # End-to-end pipeline
â”‚
â”œâ”€â”€ demo.py                # Live interview demo
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

âš™ï¸ Setup & Installation
1ï¸âƒ£ Install Python Dependencies
pip install -r requirements.txt

2ï¸âƒ£ Download NLP Resources
python -m nltk.downloader punkt
python -m nltk.downloader punkt_tab
python -m spacy download en_core_web_sm


3ï¸âƒ£ Install Ollama & Lightweight LLM
Install Ollama from: https://ollama.com
ollama pull phi3

Why Phi-3?
Chosen deliberately for low memory usage, CPU friendliness, and fast local inference, making the system practical on student laptops.

ğŸš€ Running the System
Step 1 â€” Build Semantic Chunks & Knowledge Graph
python -m src.pipeline.ambedkargpt

Typical output:
Semantic Chunking Complete
Total Chunks: ~300
Knowledge Graph Built
Nodes: ~1400
Edges: ~1500
Communities: ~400+

Step 2 â€” Live Question Answering Demo
python demo.py

Try questions like:
What was Ambedkarâ€™s view on caste?
Why did Ambedkar criticize the Hindu social order?
What is Ambedkarâ€™s idea of social justice?


ğŸ›‘ Hallucination Prevention (Important)

If a question is outside the scope of Ambedkarâ€™s writings, the system refuses to answer:
â€œI cannot answer this question because it is not covered in Dr. B. R. Ambedkarâ€™s writings.â€

How this woEmbedding similarity is used as a relevance confidence gate
- If retrieved context is weak, LLM invocation is skipped
- This makes the system safer and production-oriented

  ğŸ§ª What This Project Demonstrates

- Research-to-code translation (SemRAG paper â†’ working system)
- Practical NLP engineering decisions
- Graph-based reasoning beyond vector search
- Responsible LLM usage (hallucination control)
- Clean, modular, extensible design
